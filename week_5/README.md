# Artificial Neural Networks

An Artificial Neural Network is a paradigm inspired by the way biological nervous systems work. It consists of multiple layers of simple processing elements called neurons. Neurons have two functions: Collecting inputs and generating an output.

A neural network contains a large number of interconnected neurons. Neural describes the precense of neurons, and network describes a graph like structure if connections.

These type of systems should be directed graphs where nodes perform simple computations. Each connection conveys a signal and they are labeled by a strength, also known as weight.

Each neuron is a relatively simple non-linear function. Systems with many neurons can generate complex and interesting behaviors. Each node output depends on information locally available, either stored at the node or arriving from the weighted connections.

By themselves, neurons are not very powerful, they generate a single scalar numerical value. However, when they are connected in a network, they can perform complex computations.
Each neuron performs two functions: Aggregation and Generation.

In Biology, receptors are called dentrites, while effectors are called axons. The cell body is called soma. The axon is connected to the dendrites of other neurons. The connection between the axon and the dendrite is called synapse. The synapse is the connection between the axon of one neuron and the dendrite of another neuron.

## Methodology

ANNs are parallel computational models. These models are very sensitive to the size of data. The quality of the results entirely depends on having a significant portion of data that actually represents the phenomena that is being modeled, while at the same time, noisy data should be avoided.

ANNs are the best method when a problem is poorly understood but there is a lot of data available. They do not solve a problem in a mathematical sense, but rather generate an approximation of the solution based on the data. 

Neural Netwokrs are widely used applications such as:
- Complex non linear function
- Pattern recognition
- Classification
- Image processing
- Prediction
- System identification
- Control

One of the most popular types of ANNs are the Fed Forward Neural Networks (FFNN). They consist of an input layer, some hidden layers with synaptic weights, and an output layer. These neural networks are modeled with three basic elements:
- A set of synapses, each of which is characterized by a weight
- An adder, or linear combiner, that sums the inputs to the neuron
- An activation function that limits the amplitude of the output of the neuron

The later may be increased by using a bias term.

Also, a Multi Layer Perceptron Neural Network is an architecture of FFNN, where the designer chooses the following features:

- Topology
- Performance function
- Learning rule
- Criteria for stopping the learning process

However, the system automatically determines the weights of the synapses.

ANNs are extremely efficient in terms of development time and resources, providing performance that is hardly comparable to other methods. However, they are not very good at generalizing known rules such as physics, and they are overshadowed by physics aware methods.

A functional model like this is a black box, and it is not possible to know what is happening inside. This is a problem when it comes to explainability, as it is not possible to know why the model is making certain decisions.

Alos, when dealing with weighted synapses we can identify two escenarios:
- Negative weights: Inhibitory synapses
- Positive weights: Excitatory synapses

An activation function is usually limiting the amplitude of the output to either between 0 and 1, or -1 and 1. This is done to avoid saturation of the neuron.

The internal activity of the neuron may be represented as:

$$
v_k = \sum_{j=1}^{p} w_{kj} x_j
$$

Where $v_k$ output of the neuron, $y_k$ is the internal result of the aggregation, $w_{kj}$ is the synaptic weight, and $x_j$ is the input to the neuron.

Finally, a Fed Forward Neural Network has a constraint to only allow connections between layers, and not within layers. They're usually represented using the number of neurons in each layer, such as 3-5-2, where the first layer has 3 neurons, the second layer has 5 neurons, and the third layer has 2 neurons. They generally have no more than 4 layers.

## Learning

In the context of ANNs, learning is the process of adjusting the synaptic weights of the network. Random values are adapted as parameters via a continuous simulation.

There are three types of learning:
- Supervised learning
- Unsupervised learning
- Reinforcement learning

## Supervised Learning

Inputs are matched with the desired outputs. These inputs may be provided by an external agent, or they may be generated by the system itself (self-supervised). The system then compares the desired output with the actual output, and adjusts the weights accordingly; this is called error backpropagation.

## Unsupervised Learning

The system is trainned to respond to clusters and patterns that are apparent within the data itself. The system tries to discover statistically salient features and develops its own representation of input stimuli. This is called self-organization.

## Reinforcement Learning

The system generates an action in the environment and gets feedback interpreted as a reward or punishment. The system then adjusts the weights to maximize the reward until equilibrium is reached.

## Training 

It's possible to use non-linear log-sigmoid activation functions to simulate non-linear behavior. 

ANNs usually have two phases:
- Training
- Testing

Backprograpation usually involves gradient descent as an optimization method for training.

The topology and architecture of the network is usually determined by trial and error.

One of the problems that may arise is overfitting, which is when the network is too complex for the problem at hand, causing it to aim for a very small error but generating predictions with a high variance, therefore, memorizing the training data instead of learning to generalize from it.

To improve this there are a coupe of techniques:
- Early stopping: Stop training when the error on the validation set starts to increase.
- Regularization: Add a penalty term to the error function to avoid large weights.

We may denote the performance of the network as:

$$
mse = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2
$$

Where $N$ is the number of samples, $y_i$ is the actual value, and $\hat{y}_i$ is the predicted value.

Then its possible to include a term that accounts for the sum of squares of the weights and biases:

$$
msw = \frac{1}{N} \sum_{j=1}^{N} w_j^2
$$

Where $w_j$ is the weight or bias.

Then, the mean squared error can be modified to include the sum of squares of the weights and biases:

$$
msereg =  \lambda mse + (1 - \lambda) msw
$$

Where $\lambda$ is a parameter that controls the relative importance of the two terms.

Using this function causes the network to learn the data while keeping the weights small, therefore, generating smoother and les likely to overfit predictions.

## Experiment results

In the experiment one it's possible to see a simple setup of a neural network solving a XOR problem. The network had some trouble converging with only 10000 epochs, generating a prediction of 0.5 for all inputs. However, after increasing the number of epochs to 16000, the network was able to converge to the correct solution.

The second experiment is an example of a much more complex task by implementing specific techniches for image classification. And even when the epoch number is much lower, the network is able to converge to a solution. This is because the network is much more complex, having larger layers, and the data is much more representative of the problem at hand. The model achieves an accuracy of 91.15% in only 10 epochs.